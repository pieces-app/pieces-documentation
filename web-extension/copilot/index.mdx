---
title: "Copilot"
---

***

## Generative AI Conversations

If you're unsure how to implement something, stuck on a bug, or need an answer within your workspace, use the Pieces Copilot for context-aware responses to help you move forward.

The Pieces Web Extension offers several levels of conversation functionality, all fully integrated with Pieces.

You can enable the [**Long Term Memory Engine (LTM-2)**](https://docs.pieces.app/products/meet-pieces/fundamentals#ltm-2) for complete, streamlined context across your workflow or open a limited context conversation in the browser's view.

<Image src="https://storage.googleapis.com/hashnode_product_documentation_assets/web_extension/pieces_copilot/_MAIN/hover_copy_save.png" alt="" align="center" fullwidth="true" />

## Adding Conversation Context

The Pieces Copilot lets you add specific folders or files to the conversation's context window, like files from your current workspace.

You can add individual external items as context to your chat from within the Pieces Copilot view.

<Callout type="info">
  This differs from starting a chat using one of the embedded buttons under a code snippet, such as on Stack Overflow (see the image below).
</Callout>

<Image src="https://storage.googleapis.com/hashnode_product_documentation_assets/web_extension/pieces_copilot/_MAIN/hovering_ask_copilot_QA.png" alt="" align="center" fullwidth="true" />

To start a conversation that’s pre-loaded with context, find a code snippet on a website such as Stack Overflow or your favorite code platforms and select the `Ask Copilot` quick action beneath it.

## Selecting Your Pieces Copilot Runtime

You can choose between [different LLMs directly within the Pieces Web Extension](https://docs.pieces.app/products/web-extension/copilot/llm-settings) by accessing the sidebar and clicking on your preferred model under `Active Model` (e.g., *Claude 3.5 Sonnet*).

Options range from lightweight models for simple queries to advanced models for detailed analysis, including [local](https://docs.pieces.app/products/large-language-models/local-models) and [cloud-based LLMs](https://docs.pieces.app/products/large-language-models/cloud-models).

This flexibility lets you customize Pieces Copilot to fit your specific development needs, whether you prioritize speed or accuracy.

<Image src="https://storage.googleapis.com/hashnode_product_documentation_assets/web_extension/pieces_copilot/_MAIN/changing_llm.gif" alt="" align="center" fullwidth="true" />

Read more about [what LLMs are available](https://docs.pieces.app/products/large-language-models) with the Pieces Web Extension.

## Pieces Copilot As a Daily Driver

The Pieces Copilot is a powerful, adaptable tool that grows with you as you use it—*so use it!*

***

<AccordionGroup>
  <Accordion title="Collaborative Sharing Made Easy">
    Generate detailed comments and documentation for better team collaboration and also reduce onboarding times, creating a unified coding style across teams.
  </Accordion>

  <Accordion title="Quick Prototyping">
    Generate initial implementations and boilerplate code for prototypes and fast-paced projects. Ideal for hackathons, PoCs, and other time-sensitive tasks.
  </Accordion>

  <Accordion title="Skill Enhancement">
    Pieces Copilot doubles as a learning tool, helping you explore best practices, new paradigms, and advanced techniques in real-time.
  </Accordion>
</AccordionGroup>

***

[Download the Pieces Web Extension Today!](https://docs.pieces.app/products/web-extension/get-started#supported-browsers)
