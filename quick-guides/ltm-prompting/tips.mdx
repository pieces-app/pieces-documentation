---
title: "General Long-Term Memory Prompting Tips"
description: "Here are some general prompting tips to help you get the most out of Pieces."
---

---

## In This Guide

Generative AI can only be _so_ smart, but you can extract a lot more usefulness out of LLMs—especially when they’re served through Pieces, with the power of LTM-2—by adjusting your prompts.

This prompt guide will cover some of the more basic, but still quite important, of prompting so that you maximize the potential of LTM-enhanced in your workflow.

## Prompt by Keyword

When Pieces searches its Long-Term Memory, it is more likely to find relevant context when you use unique expressions that are relevant to the memories you are interested in.

For example, if you want to use memories for a project called "Gonk," a prompt like "What is the status of project Gonk?" will help Pieces focus only on the memories related to that project.

If you simply ask, "What is the status of my project?" then Pieces might consider multiple projects you have worked on, in which case you might get a mixed bag of results.

<tip>
  If you can't recall keywords like project, ticket, or package names, Pieces can help\! Ask, "Give me the titles of all the project documents I've been working on," and you can specify a time range like "last month." This helps find keywords for more specific prompts.
</tip>

## Prompt by Time Range

Pieces stores up to 9 months of memories. To help narrow down the memories, you can include a time range in your prompt. This allows Pieces to focus on exactly what you need.

For example, you can ask, “What was I doing last week?” or “What were the plans I received from Scarif in December?”

## Prompt by Source Application

When Pieces captures memories, it also captures the application name that the memories came from—this allows you to ask specific questions related to the source application.

Try using a prompt like “Summarize my discussions with Rey Skywalker in Teams” to separate conversations with a colleague in Teams from those in emails or document comments.

## Mix Prompt Types

The more context Pieces has, the more it can narrow down to the right memories to use when responding to your prompts.

You can mix and match keywords, time ranges, and applications to get very accurate responses.

Ask, “What is the URL for the Project Darklighter document I discussed in Teams with Biggs last Thursday?” This helps distinguish it from documents shared by others, in different apps, or at other times.

<tip>
  Prompt mixing is extremely useful—not only are you narrowing down the search by providing specific keywords, but you improve the accuracy of that search by also excluding other ranges or species of data.
</tip>

## Use the Source and Time Range Filters

If you know the source application or time range you want to access in your prompts, a quick and accurate way to use them is through the filters.

This lets you filter by source applications or a time range using a set of predefined ranges or a custom picker. This method can be more accurate than using prompts because there are many ways to express time concepts.

## Start New Copilot Chats When you Change Topic

Rule of thumb—if you change topic, start a new copilot chat.

When you are in a Pieces Copilot chat, Pieces will extract the relevant memory context for the questions you ask, and use this across the entire conversation.

If you change topics, then the memories available in the chat may not be relevant, so you may get better results by starting a new chat.