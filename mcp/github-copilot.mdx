---
title: " Pieces MCP + GitHub Copilot"
description: "The Pieces MCP (Model Context Protocol) integration with GitHub Copilot allows you to leverage Pieces Long-Term Memory (LTM) directly within the Visual Studio Code editor, enhancing your coding workflow with seamless contextual information retrieval."
---

---

![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_gh_copilot/mcp-2-1.png)

---

## Get Started

Connecting [Pieces MCP](https://docs.pieces.app/products/mcp/get-started) to **GitHub Copilot** enhances context-aware coding by linking your current task with past work.

This integration allows Copilot to provide insights like past implementations and peer-reviewed solutions.

You can ask context-rich questions, and Copilot can find answers from your local development history without searching through commits or messages.

Follow the steps below to enable the Pieces MCP integration with GitHub Copilot for smarter, personalized AI assistance.

## Prerequisites

There are **[2]** primary prerequisites for integrating Pieces with GitHub Copilot as an MCP—an active instance of **PiecesOS** and the fully-enabled **Long-Term Memory** engine.

<Steps>
  <Step title="Install & Run PiecesOS">
    Make sure that PiecesOS is installed and running. This is _required_ for the MCP server to communicate with your personal repository of workflow data and pass context through to the GitHub Copilot chat agent.

    If you do not have PiecesOS, you can download it alongside the [Pieces Desktop App](https://docs.pieces.app/products/desktop/download) or [install it standalone](https://docs.pieces.app/products/core-dependencies/pieces-os/manual-installation#manual-download--installation) here.
  </Step>
  <Step title="Enable Long-Term Memory">
    For the MCP server to interact with your workflow context, you must enable the Long-Term Memory Engine (LTM-2) through the Pieces Desktop App or the [PiecesOS Quick Menu](https://docs.pieces.app/products/core-dependencies/pieces-os/quick-menu) in your toolbar.
  </Step>
</Steps>

### Installing PiecesOS & Configuring Permissions

Follow the detailed set-up instructions below for a detailed guide on setting up and configuring PiecesOS to correctly pass captured workflow context to the Pieces MCP server.

<Tabs>
  <Tab title="macOS">
    **Installing PiecesOS for macOS**

    [Download the standalone PiecesOS file](https://docs.pieces.app/products/core-dependencies/pieces-os/manual-installation#macos) for your macOS system’s ARM or Intel-based architecture to start the installation process.

    _Your device must be updated to macOS 13.0 (Ventura) or higher._

    1. Download the correct PiecesOS file for your system’s architecture.
    2. From your **Downloads** folder, double-click the installed PiecesOS file to open it.
    3. Drag PiecesOS into the application folder if prompted, then open PiecesOS.

    **Configuring Permissions**

    There are two permissions prompts that will pop up on your screen when installing PiecesOS.

    > _PiecesOS is an app downloaded from the internet. Are you sure you want to open it?_

    Click `Open` to continue with the installation.

    Then, you’ll see a second permissions pop-up message:

    > PiecesOS is requesting to bypass the system private window picker and directly access your screen and audio. This will allow PiecesOS to record your screen and system audio, including personal or sensitive information that may be visible or audible.

    Click `Allow`.

    These permissions are required for [PiecesOS](https://docs.pieces.app/products/core-dependencies/pieces-os) to power the [Long-Term Memory Engine (LTM-2)](https://docs.pieces.app/products/core-dependencies/pieces-os#ltm-2) and, in turn, capture context from your workflow to provide information to the [Pieces MCP server.](https://docs.pieces.app/products/mcp/get-started)

    PiecesOS will automatically open in your toolbar and pop up a _Notification preferences modal_ in the upper right corner of your screen.

    **Enabling the LTM-2 Engine**

    For the Pieces MCP to function, Long-Term Memory must be enabled.

    To do this, open up the PiecesOS Quick Menu and click `Enable Long-Term Memory Engine`.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/misc_fragments_media/macos_piecesOS_toolbar.png)
  </Tab>
  <Tab title="Windows">
    **Installing PiecesOS for Windows**

    [Download the standalone PiecesOS file](https://docs.pieces.app/products/core-dependencies/pieces-os/manual-installation#windows) for your Windows machine to start the installation process.

    _Your device must be updated to Windows 10 (20HO) or higher._

    1. Download the file.
    2. From your **Downloads** folder, double-click the installed PiecesOS file to open it.
    3. Click `Yes` when the _User Account Control_ modal pops up on your screen to proceed with the installation.

    **Note:** Some users who have enabled Controlled Folder Access (CFA) as a security measure may receive a notification that Pieces is attempting to bypass this security wall.

    PiecesOS uses vision processing to ingest context from foreground applications horizontally. To decide which apps PiecesOS has access to, you can [easily enable and disable specific sources](https://docs.pieces.app/products/core-dependencies/pieces-os/quick-menu#long-term-memory-access-control) from the Long-Term Memory Access Control panel.

    4. Choose your installation location and click `Next`.
    5. Click `Install`, then `Finish` when the progress bar has finished loading.
    6. Follow the installer’s instructions, selecting a download location and preferred file path as necessary.

    PiecesOS will launch when the installation process is completed, and can be found in your Windows _System Tray_ at the bottom left corner of your screen.

    **Enabling the LTM-2 Engine**

    For the Pieces MCP to function, Long-Term Memory must be enabled.

    To do this, open up the PiecesOS Quick Menu and click `Enable Long-Term Memory Engine`.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/misc_fragments_media/windows_piecesOS_toolbar.png)
  </Tab>
  <Tab title="Linux">
    **Installing PiecesOS for Linux**

    To download and install PiecesOS _and_ utilize the Long-Term Memory Engine (LTM-2) on your Linux device, you must meet **(4)** requirements.

    - **Snap Support:** Ensure `snapd` is installed and enabled on your system. Most recent Ubuntu releases include `snapd` by default. If needed, install `snapd` by following the official `snapd` documentation.
    - **Administrator Access:** You’ll need `sudo` privileges to install `snap` packages.
    - **Minimum OS Type:** PiecesOS has been tested and developed primarily for Ubuntu 22\+ or later-based distributions, so make sure your system is updated to at least Ubuntu 22\+ or later.
    - **X11 Window Manager:** Virtual Linux machines or dedicated instances of Linux, even PiecesOS-compatible Ubuntu 22\+ distributions, _must utilize_ **X11** as the proprietary Window Manager. To determine which display manager your Linux device is using, go to **Settings,** then **System,** and **System Details** to see if you are using an X11 or a non-LLVM compatible manager.

    **_Note:_** _Ubuntu 22\+ using the X11 Window Manager is required_ to install PiecesOS and use LTM.

    Run these commands **to install and set up PiecesOS properly**.

    1. Open the Command-Line Interface (CLI) using the `ctrl+alt+t` keyboard shortcut.
    2. Run `sudo snap install pieces-os` to install PiecesOS. You will be prompted to enter your local account’s password.
    3. Enter and run `sudo snap connect pieces-os:process-control :process-control` to enable offline and on-device machine learning and large language model (LLM) functionality.

    **Note:** Make sure to run the above permissions-related commands. These are required for the [Long-Term Memory Engine (LTM-2)](https://docs.pieces.app/products/core-dependencies/pieces-os#ltm-2) to capture context from your workflow to serve the [Pieces MCP](https://docs.pieces.app/products/mcp/get-started).

    To launch PiecesOS, type `pieces-os` in your terminal and press `enter`.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/misc_fragments_media/linux_piecesOS_toolbar.png)
  </Tab>
</Tabs>

### SSE Endpoint

To use Pieces MCP with GitHub Copilot, you first need the Server-Sent Events (SSE) endpoint from PiecesOS:

```markdown
http://localhost:39300/model_context_protocol/2024-11-05/sse
```

<Warning>
  Keep in mind that the **specific port** (i.e., `39300`) PiecesOS is running on **may vary**.
</Warning>

To find the current SSE endpoint with the active instance of POS (including the current port number), open the PiecesOS Quick Menu and expand the **Model Context Protocol (MCP) Servers** tab.

There, you can copy the SSE endpoint with one click, which includes the active PiecesOS port number.

![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_pos_new.png)

You can also do this in the Pieces Desktop App by opening the **Settings** view and clicking **Model Context Protocol (MCP).**

![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_pfd_new.png)

## Setting Up GitHub Copilot

You can now use the Pieces MCP with both Visual Studio Code and Visual Studio Code (Insider Edition).

Follow the steps below to get started—or watch the video below for a set-up tutorial and live demo.

<iframe width="734" height="413" src="https://www.youtube.com/embed/QT9J8XSKMM8" title="Using Pieces MCP (Model Context Protocol) with GitHub Copilot in VS Code" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen />

### via Visual Studio Code UI

Adding the Pieces MCP in the built-in MCP menu is the easiest method to setting up your Pieces MCP server and allows you to have the best experience while using the Pieces MCP.

<Steps>
  <Step title="Open the Command Palette">
    Open Visual Studio Code and launch the Command Palette by pressing `Cmd+Shift+P` on macOS or `Ctrl+Shift+P` on Windows/Linux.
  </Step>
  <Step title="Add a New MCP Server">
    In the Command Palette, type **MCP: Add Server** and select the command when it appears.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_gh_copilot/mcp_add_server_dropdown.png)
  </Step>
  <Step title="Choose the Server Type">
    Select `HTTP (sse)` as the server type when requested.
  </Step>
  <Step title="Enter the SSE URL">
    Paste your SSE URL into the provided field.

    For Pieces, use:

    ```plaintext
    http://localhost:39300/model_context_protocol/2024-11-05/sse
    ```

    <info>
  Remember to grab the specific SSE URL (with the *active* PiecesOS port) from either the PiecesOS or Pieces Desktop App MCP menu.
</info>
  </Step>
  <Step title="Enter a MCP Server Name">
    When prompted to add a new MCP server, enter a name for your server, such as ‘Pieces\` or something easy to remember.

    Then, you can select the `User Settings` option to save the MCP server configuration in your VS Code user settings, so it can be accessed globally across different workspaces—or choose `Workspace Settings` to use it explicitly in your open project.
  </Step>
  <Step title="Save Your Configuration">
    Save your configuration. Your VS Code `settings.json` file should now include an entry similar to the example below:

    ```json
    {
      "mcpServers": {
        "Pieces": {
          "url": "http://localhost:39300/model_context_protocol/2024-11-05/sse"
        }
      }
    }
    ```

    Your GitHub Copilot chat, as long as the chat mode is in _Agent_ mode, will now see Pieces as an MCP and automatically utilize the `ask_pieces_ltm` tool on-query.
  </Step>
</Steps>

### via Global MCP Configuration

You can manually add the MCP to your MCP settings `.JSON` by following the steps below.

<Steps>
  <Step title="Open the Visual Studio Code Settings">
    Click the **Settings Icon** on the bottom left of your IDE and select `Settings` from the list.
  </Step>
  <Step title="Search for MCP">
    In the VS settings, search for MCP in the search bar at the top of the page. The MCP section will appear—then, select `Edit in settings.json`.
  </Step>
  <Step title="Add the MCP Server Config .JSON">
    Replace the entire file, assuming you have no others, with the PiecesOS MCP server `.json`.

    ```json
    {
      "mcpServers": {
        "Pieces": {
          "url": "http://localhost:39300/model_context_protocol/2024-11-05/sse"
        }
      }
    }
    ```
  </Step>
  <Step title="Save the File">
    Save the configuration.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_gh_copilot/mcp_settings.png)

    Your GitHub Copilot chat, as long as it’s in Agent mode, will now see PiecesOS as an MCP.
  </Step>
</Steps>

## Using Pieces MCP Server in GitHub Copilot

Once integrated, you can utilize Pieces LTM directly in Visual Studio Code.

<Steps>
  <Step title="Open GitHub Copilot Chat">
    Launch the GitHub Copilot chat interface in Visual Studio Code by clicking the Copilot icon, or by using `⌘+ctrl+i` (macOS) `ctrl+alt+i` (Windows/Linux).

    Change the Copilot mode from _Ask_ to _Agent_.
  </Step>
  <Step title="Start Prompting">
    Enter your prompt, and click the **send** icon or press `return` (macOS) or `enter` (Windows/Linux) to send your query to the Copilot.

    ![](https://storage.googleapis.com/hashnode_product_documentation_assets/mcp_documentation/mcp_gh_copilot/chatting_with_mcp.gif)

    <Warning>
      Do not add the `ask_pieces_ltm` tool as _context_ to the conversation. If you are running the chat in _Agent_ mode—which is required for the Pieces MCP integration to operate successfully—it will automatically utilize this tool.
    </Warning>
  </Step>
</Steps>

<Card title="Hey!">
  Check out this [MCP-specific prompting guide](https://docs.pieces.app/products/mcp/prompting) if you want to effectively utilize the Long-Term Memory Engine (LTM-2) with your new Pieces MCP server.
</Card>

## Troubleshooting Tips

If you’re experiencing issues integrating Pieces MCP with GitHub Copilot, follow these troubleshooting steps:

1. **Verify PiecesOS Status**: Ensure [PiecesOS is actively running](https://docs.pieces.app/products/core-dependencies/pieces-os/troubleshooting) on your system. MCP integration requires PiecesOS to be operational.
2. **Confirm LTM Engine Activation**: Make sure the [Long-Term Memory Engine (LTM-2) is enabled in PiecesOS](https://docs.pieces.app/products/core-dependencies/pieces-os/quick-menu#ltm-2-engine), as this engine aggregates context necessary for Cursor to retrieve accurate results.
3. **Use Agent Mode in Chat**: Cursor must be in _Agent_, not _Ask_, to access the `ask_pieces_ltm` tool. Switch to Agent to enable full MCP integration. Make sure _not to add_ the `ask_pieces_ltm` tool as context—instead, rely solely on the _Agent_ chat mode.
4. **Single MCP Instance:** Make sure that you aren’t testing multiple instances of the Pieces MCP server in different IDEs. This cross-contamination conflict with the SSE and several MCP instances running on the same port can cause issues in different development environments.
5. **Check MCP Server Status**: If you’re encountering messages such as “Sorry, I can’t do this,” your MCP server may not be properly configured or running.
6. **Go to** `settings.json` **in Visual Studio Code:** Confirm the MCP server status shows "running" (it may say "start" or "pause" otherwise). Restart the server if necessary and inspect terminal outputs for error messages.
7. **Review Configuration Details**: Double-check the MCP endpoint URL and the port number in your VS Code MCP configuration menu to ensure accuracy. You can find the current SSE endpoint URL in the Pieces Desktop App under **Settings** → **Model Context Protocol (MCP)**, or in the PiecesOS Quick Menu. It is usually formatted as:

```scss
http://localhost:{port_number}/model_context_protocol/{version}/sse
```

---

You're now ready to improve your workflow with powerful context retrieval using Pieces MCP, seamlessly integrated into Visual Studio Code with GitHub Copilot. Happy coding\!