---
sidebarTitle: "LLM Settings"
---

---

## Available LLMs

We constantly update and configure our plugins and extensions, like the Pieces for Obsidian Plugin, to <a target="_blank" href="https://github.com/pieces-app/support/discussions/121">
work with the latest LLMs</a>

.

Click here to see all [54\+ local and cloud-hosted models available](https://docs.pieces.app/products/large-language-models) for use with the Pieces for Obsidian Plugin.

## How To Configure Your LLM Runtime

Switching your LLM model in the Pieces Web Extension is

You can choose the model that best suits your needs, such as whether you need a model with a large context window for a specific task or series of prompts, or prefer speed over accuracy.

How to change your LLM:

<Steps>
  <Step title="Open the Copilot Chat View">
    Open the Copilot Chat view by clicking the `Pieces Icon` in the extensions section of your browser.
  </Step>
  <Step title="Locate the Active Model">
    Find the **Active Model** in the bottom-left corner of the view, where the current model (e.g., _GPT-4o Mini_) is shown.

    <img
      className="mx-auto"
    />
  </Step>
  <Step title="View the Models">
    Click on `Change Model` to open the **Manage Copilot Runtime** modal.
  </Step>
  <Step title="Choose your Desired Model">
    Browse the list of local and cloud models, and select your preferred model.
  </Step>
</Steps>

Switching between the cloud and desktop icons allows you to browse and select from various available cloud and local models.

<tip>
  Cloud-hosted models offer access to the latest AI capabilities, while on-device models ensure offline functionality, making Pieces Copilot adaptable to your specific workflow and environment.
</tip>

Once you choose a new model, the switch is instant, allowing you to continue working smoothly with the latest model's features without restarting or refreshing anything.

<img
  className="mx-auto"
/>