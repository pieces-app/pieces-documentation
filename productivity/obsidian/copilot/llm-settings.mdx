---
sidebarTitle: "LLM Settings"
---

---

## Available LLMs

We constantly update and configure our plugins and extensions, like the Pieces for Obsidian Plugin, to <a target="_blank" href="https://github.com/pieces-app/support/discussions/121">
work with the latest LLMs</a>

.

Click here to see all [54\+ local and cloud-hosted models available](https://docs.pieces.app/products/large-language-models) for use with the Pieces for Obsidian Plugin.

## How To Configure Your LLM Runtime

Switching your LLM model in the Pieces for Obsidian Plugin is straightforward. You can choose the model that best suits your needs.

How to change your LLM:

<Steps>
  <Step title="Open the Copilot Chat View">
    Open the Copilot Chat view by clicking the `Pieces Copilot Icon` in the sidebar.
  </Step>
  <Step title="Locate the Active Model">
    Locate the **Active Model** in the bottom-left corner of the view, where the current model (e.g., _GPT-4o Mini_) is displayed.

    <img
      className="mx-auto"
    />
  </Step>
  <Step title="View the Models">
    Click on `Change Model` to open the **Manage Copilot Runtime** model.
  </Step>
  <Step title="Choose your Desired Model">
    Browse the list of local and cloud models, and select your preferred model.
  </Step>
</Steps>

You can browse and select from various available models, such as the local and cloud-based models listed [in the table at the top of this page.](https://docs.pieces.app/products/obsidian/configuration#supported-llms)

Once you’ve chosen a new model, the switch is instant, allowing you to continue your work seamlessly with the selected model's capabilities—_no need to restart or refresh anything._

<img
  className="mx-auto"
/>

<tip>
  Cloud-hosted models offer access to the latest AI capabilities, while on-device models ensure offline functionality, making Pieces Copilot adaptable to your specific workflow and environment.
</tip>