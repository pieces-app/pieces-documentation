---
sidebarTitle: "What is Ollama?"
---

| **Feature**              | **Cloud AI (Default)**                                                                                      | **Local AI (Ollama)**                                  |
| ------------------------ | ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ |
| **Processing Location**  | Cloud-based (requires internet)                                                                             | On-device (runs locally)                               |
| **Performance**          | Dependent on internet speed                                                                                 | Potentially faster response times (no network latency) |
| **Data Privacy**         | Data only sent to cloud if included as context in a Copilot Chatâ€”reverts on OpenAI, Gemini Privacy Policies | 100% local (no data transmission from local device)    |
| **Model Availability**   | Uses several cloud-hosted models                                                                            | Uses user-installed local models                       |
| **Storage Requirements** | Minimal outside of the PiecesOS installation                                                                | Several GBs (model storage)                            |
| **Offline Support**      | No                                                                                                          | Yes                                                    |

---